{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anaconda\\anaconda3\\lib\\site-packages\\IPython\\core\\magics\\pylab.py:159: UserWarning: pylab import has clobbered these variables: ['plt']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  warn(\"pylab import has clobbered these variables: %s\"  % clobbered +\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('../futures_limited/*.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../futures_limited\\\\minute-AC.txt',\n",
       " '../futures_limited\\\\minute-AD.txt',\n",
       " '../futures_limited\\\\minute-AEX.txt',\n",
       " '../futures_limited\\\\minute-BD.txt',\n",
       " '../futures_limited\\\\minute-BL.txt',\n",
       " '../futures_limited\\\\minute-BO.txt',\n",
       " '../futures_limited\\\\minute-BP.txt',\n",
       " '../futures_limited\\\\minute-BR.txt',\n",
       " '../futures_limited\\\\minute-BTP.txt',\n",
       " '../futures_limited\\\\minute-BX.txt',\n",
       " '../futures_limited\\\\minute-C.txt',\n",
       " '../futures_limited\\\\minute-CC.txt',\n",
       " '../futures_limited\\\\minute-CD.txt',\n",
       " '../futures_limited\\\\minute-CL.txt',\n",
       " '../futures_limited\\\\minute-CN.txt',\n",
       " '../futures_limited\\\\minute-CRD.txt',\n",
       " '../futures_limited\\\\minute-CT.txt',\n",
       " '../futures_limited\\\\minute-DA.txt',\n",
       " '../futures_limited\\\\minute-DX.txt',\n",
       " '../futures_limited\\\\minute-EB.txt',\n",
       " '../futures_limited\\\\minute-EMD.txt',\n",
       " '../futures_limited\\\\minute-ES.txt',\n",
       " '../futures_limited\\\\minute-EU.txt',\n",
       " '../futures_limited\\\\minute-EX.txt',\n",
       " '../futures_limited\\\\minute-EZ.txt',\n",
       " '../futures_limited\\\\minute-FV.txt',\n",
       " '../futures_limited\\\\minute-GC.txt',\n",
       " '../futures_limited\\\\minute-GF.txt',\n",
       " '../futures_limited\\\\minute-HE.txt',\n",
       " '../futures_limited\\\\minute-HG.txt',\n",
       " '../futures_limited\\\\minute-HO.txt',\n",
       " '../futures_limited\\\\minute-IHO.txt',\n",
       " '../futures_limited\\\\minute-IN.txt',\n",
       " '../futures_limited\\\\minute-JY.txt',\n",
       " '../futures_limited\\\\minute-KC.txt',\n",
       " '../futures_limited\\\\minute-KPO.txt',\n",
       " '../futures_limited\\\\minute-LB.txt',\n",
       " '../futures_limited\\\\minute-LE.txt',\n",
       " '../futures_limited\\\\minute-LF.txt',\n",
       " '../futures_limited\\\\minute-LG.txt',\n",
       " '../futures_limited\\\\minute-LL.txt',\n",
       " '../futures_limited\\\\minute-M6E.txt',\n",
       " '../futures_limited\\\\minute-ME.txt',\n",
       " '../futures_limited\\\\minute-MME.txt',\n",
       " '../futures_limited\\\\minute-MT.txt',\n",
       " '../futures_limited\\\\minute-NE.txt',\n",
       " '../futures_limited\\\\minute-NG.txt',\n",
       " '../futures_limited\\\\minute-NIY.txt',\n",
       " '../futures_limited\\\\minute-NKD.txt',\n",
       " '../futures_limited\\\\minute-NN.txt',\n",
       " '../futures_limited\\\\minute-NOK.txt',\n",
       " '../futures_limited\\\\minute-NQ.txt',\n",
       " '../futures_limited\\\\minute-OAT.txt',\n",
       " '../futures_limited\\\\minute-OJ.txt',\n",
       " '../futures_limited\\\\minute-PA.txt',\n",
       " '../futures_limited\\\\minute-PG.txt',\n",
       " '../futures_limited\\\\minute-PL.txt',\n",
       " '../futures_limited\\\\minute-PX.txt',\n",
       " '../futures_limited\\\\minute-QC.txt',\n",
       " '../futures_limited\\\\minute-QM.txt',\n",
       " '../futures_limited\\\\minute-RA.txt',\n",
       " '../futures_limited\\\\minute-RB.txt',\n",
       " '../futures_limited\\\\minute-RR.txt',\n",
       " '../futures_limited\\\\minute-RS.txt',\n",
       " '../futures_limited\\\\minute-RTY.txt',\n",
       " '../futures_limited\\\\minute-RU.txt',\n",
       " '../futures_limited\\\\minute-S.txt',\n",
       " '../futures_limited\\\\minute-SB.txt',\n",
       " '../futures_limited\\\\minute-SEK.txt',\n",
       " '../futures_limited\\\\minute-SF.txt',\n",
       " '../futures_limited\\\\minute-SI.txt',\n",
       " '../futures_limited\\\\minute-SM.txt',\n",
       " '../futures_limited\\\\minute-SPI.txt',\n",
       " '../futures_limited\\\\minute-SS.txt',\n",
       " '../futures_limited\\\\minute-SW.txt',\n",
       " '../futures_limited\\\\minute-TU.txt',\n",
       " '../futures_limited\\\\minute-TW.txt',\n",
       " '../futures_limited\\\\minute-TY.txt',\n",
       " '../futures_limited\\\\minute-UB.txt',\n",
       " '../futures_limited\\\\minute-US.txt',\n",
       " '../futures_limited\\\\minute-VX.txt',\n",
       " '../futures_limited\\\\minute-W.txt',\n",
       " '../futures_limited\\\\minute-WIN.txt',\n",
       " '../futures_limited\\\\minute-XG.txt',\n",
       " '../futures_limited\\\\minute-XT.txt',\n",
       " '../futures_limited\\\\minute-YM.txt',\n",
       " '../futures_limited\\\\minute-YT.txt']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "products_ = [\"AD\", \"BP\",\"C\", \"CD\",\"CL\",\"DX\",\"EMD\",\"ES\",\"EU\",\"FV\",\"GC\",\"HG\",\"JY\",\"NE\",\"NG\",\"NQ\",\"RB\",\"S\",\"SF\",\"SI\", \"TU\", \"TY\",\"UB\", \"US\", \"YM\"]+\\\n",
    "['PL', 'PX', 'W', \"HE\", 'GF', 'BR', 'RU', 'LB', 'RA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b834ad1a55b34e60964d853c86aad9cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=87.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "for file in tqdm(files):\n",
    "    n = file.split('-')[-1].split('.')[0]\n",
    "    if n in products_:\n",
    "        df = pd.read_csv(file)\n",
    "        dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54be75bdd7bb4de1be0941e1902efa7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=34.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(dfs))):\n",
    "    dfs[i].columns = ['date', 'time', 'open', 'high', 'low', 'close', 'volume']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/03/2010</td>\n",
       "      <td>23:01</td>\n",
       "      <td>0.8927</td>\n",
       "      <td>0.8928</td>\n",
       "      <td>0.8926</td>\n",
       "      <td>0.8926</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01/03/2010</td>\n",
       "      <td>23:03</td>\n",
       "      <td>0.8928</td>\n",
       "      <td>0.8931</td>\n",
       "      <td>0.8928</td>\n",
       "      <td>0.8931</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01/03/2010</td>\n",
       "      <td>23:04</td>\n",
       "      <td>0.8930</td>\n",
       "      <td>0.8930</td>\n",
       "      <td>0.8927</td>\n",
       "      <td>0.8927</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01/03/2010</td>\n",
       "      <td>23:05</td>\n",
       "      <td>0.8927</td>\n",
       "      <td>0.8927</td>\n",
       "      <td>0.8925</td>\n",
       "      <td>0.8925</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01/03/2010</td>\n",
       "      <td>23:06</td>\n",
       "      <td>0.8925</td>\n",
       "      <td>0.8927</td>\n",
       "      <td>0.8925</td>\n",
       "      <td>0.8927</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3232423</th>\n",
       "      <td>08/30/2019</td>\n",
       "      <td>20:54</td>\n",
       "      <td>0.6741</td>\n",
       "      <td>0.6742</td>\n",
       "      <td>0.6741</td>\n",
       "      <td>0.6741</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3232424</th>\n",
       "      <td>08/30/2019</td>\n",
       "      <td>20:55</td>\n",
       "      <td>0.6742</td>\n",
       "      <td>0.6742</td>\n",
       "      <td>0.6741</td>\n",
       "      <td>0.6741</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3232425</th>\n",
       "      <td>08/30/2019</td>\n",
       "      <td>20:56</td>\n",
       "      <td>0.6741</td>\n",
       "      <td>0.6741</td>\n",
       "      <td>0.6741</td>\n",
       "      <td>0.6741</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3232426</th>\n",
       "      <td>08/30/2019</td>\n",
       "      <td>20:58</td>\n",
       "      <td>0.6740</td>\n",
       "      <td>0.6741</td>\n",
       "      <td>0.6740</td>\n",
       "      <td>0.6740</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3232427</th>\n",
       "      <td>08/30/2019</td>\n",
       "      <td>20:59</td>\n",
       "      <td>0.6740</td>\n",
       "      <td>0.6741</td>\n",
       "      <td>0.6740</td>\n",
       "      <td>0.6740</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3232428 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               date   time    open    high     low   close  volume\n",
       "0        01/03/2010  23:01  0.8927  0.8928  0.8926  0.8926     107\n",
       "1        01/03/2010  23:03  0.8928  0.8931  0.8928  0.8931      12\n",
       "2        01/03/2010  23:04  0.8930  0.8930  0.8927  0.8927      59\n",
       "3        01/03/2010  23:05  0.8927  0.8927  0.8925  0.8925      64\n",
       "4        01/03/2010  23:06  0.8925  0.8927  0.8925  0.8927      45\n",
       "...             ...    ...     ...     ...     ...     ...     ...\n",
       "3232423  08/30/2019  20:54  0.6741  0.6742  0.6741  0.6741     115\n",
       "3232424  08/30/2019  20:55  0.6742  0.6742  0.6741  0.6741      38\n",
       "3232425  08/30/2019  20:56  0.6741  0.6741  0.6741  0.6741      12\n",
       "3232426  08/30/2019  20:58  0.6740  0.6741  0.6740  0.6740      32\n",
       "3232427  08/30/2019  20:59  0.6740  0.6741  0.6740  0.6740      10\n",
       "\n",
       "[3232428 rows x 7 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d58685cfc9e74794b97241db5d11a294",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73ca99e301ba4ef3bbc8ad1aa5bcc470",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=53873.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9a4ea1de1c548949a905cf457786f8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=51453.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afb3b61f13cd4cb6956c8a846d9c3288",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=2751.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e0d04d124d948c89724f47a2335ebb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=27005.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ee1aa8c704c4fbfb9bb8cb6773fc96f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=49639.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a592534ff7044afc9d8610b71432146a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=55742.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c505f84d5c44556a74f4b4bafa0a86b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=41515.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8dc7ba506f14c99a502e0ca2c24de59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=24916.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85b7b38970c44a0aa515542eb20daf36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=56064.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa5a302ab0374f19b47baee1d342c8a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=55421.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f938e876ccf43699cae85294ec7e2c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=45852.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a8500223c644a5dad17b5a41f467e5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=55943.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8928410174864956ba261e848be59bd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10649.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11153ff1e0cf44d38da9c96005e6f0b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=13076.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5940cc7d05641989457f4c77f582ec1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=50965.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5acfc89accb4f67a7d46709aed57041",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=54771.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7ad72e0dc2e41c693488f359f1df764",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=4305.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb1361eaeeb048a0a8da2a8e37df1f6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=37633.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37b2ab5b22d74fed99f1dae258fb4afa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=42401.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d99b887008e44fe99576b3a942570c90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=52716.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "006c6da970f740389122574eb3f5c00b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=35319.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e204b884085486886e1718ad18e8d1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=31786.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "904f91218fff4051bcfdf036c1e7afc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1796.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b38dbdbda3354056944deae09f45ed23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=30389.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c6b74e816ec4712824ab7636fa6b1f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=2427.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf051e529b7e4cf998d18a81fa02559f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=31417.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df87c2aace8747b2becbbb770a3c1024",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=44067.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ba4ea1603de417a8e1a8f36cd21876c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=50912.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3469221923f24b95abdb919fda6078f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=30952.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abdc26cfa1c04de2a28c0d9a4b964508",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=50454.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34b95b006de241ccbc68c4ffc5dedf11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=35767.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bc15339696d4a6196363fb16d9c63de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=46568.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34714ede6b124aa3bea78b9dbb4faa84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=28693.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2ad3e981b68481cbb804321aea6cf38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=51211.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ds = []\n",
    "for i, name in tqdm(zip(range(len(dfs)), products_)):\n",
    "    d = {}\n",
    "    d['open'] = []\n",
    "    d['high'] = []\n",
    "    d['low'] = []\n",
    "    d['close'] = []\n",
    "    d['volume'] = []\n",
    "    d['hour'] = []\n",
    "    d['date'] = []\n",
    "    for j in tqdm(range(0, len(dfs[i])-60, 60)):\n",
    "        vals = dfs[i].loc[j:j+60]\n",
    "        d['open'].append(vals['open'].values[0])\n",
    "        d['high'].append(max(vals['high'].values))\n",
    "        d['low'].append(min(vals['low'].values))\n",
    "        d['close'].append(vals['close'].values[-1])\n",
    "        d['volume'].append(sum(vals['volume'].values))\n",
    "        d['hour'].append(vals['time'].apply(str).values[-1].split(':')[0])\n",
    "        d['date'].append(vals['date'].apply(str).values[-1].replace('/', '-'))\n",
    "    d = pd.DataFrame(d)\n",
    "    ds.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53873\n",
      "51453\n",
      "27005\n",
      "49639\n",
      "55742\n",
      "41515\n",
      "56064\n",
      "55421\n",
      "45852\n",
      "55943\n",
      "50965\n",
      "54771\n",
      "37633\n",
      "42401\n",
      "52716\n",
      "35319\n",
      "31786\n",
      "30389\n",
      "31417\n",
      "44067\n",
      "50912\n",
      "30952\n",
      "50454\n",
      "35767\n",
      "46568\n",
      "28693\n",
      "51211\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(ds)):\n",
    "    print(len(ds[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(products_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_pop = []\n",
    "for i in range(len(ds)):\n",
    "    if len(ds[i]) < 25000:\n",
    "        to_pop.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in to_pop:\n",
    "    ds.pop(i)\n",
    "    products_.pop(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aae2409bcef24f0caa56b8abccd117c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=27.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(ds))):\n",
    "    ds[i]['datetime'] = ds[i]['date'] + ' ' + ds[i]['hour'] + ':00:00'\n",
    "    ds[i]['datetime'] = pd.to_datetime(ds[i]['datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, name in zip(range(len(ds)), products_):\n",
    "    ds[i] = ds[i].rename({k:name+\"_\"+k for k in ds[i].columns if k != 'date' and k != 'hour' and k != 'datetime'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(ds)):\n",
    "    del ds[i]['date']\n",
    "    del ds[i]['hour']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = ds[0]\n",
    "df1 = ds[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AD_open</th>\n",
       "      <th>AD_high</th>\n",
       "      <th>AD_low</th>\n",
       "      <th>AD_close</th>\n",
       "      <th>AD_volume</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8927</td>\n",
       "      <td>0.8933</td>\n",
       "      <td>0.8901</td>\n",
       "      <td>0.8909</td>\n",
       "      <td>1937</td>\n",
       "      <td>2010-01-04 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8910</td>\n",
       "      <td>0.8917</td>\n",
       "      <td>0.8887</td>\n",
       "      <td>0.8887</td>\n",
       "      <td>2148</td>\n",
       "      <td>2010-01-04 01:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.8891</td>\n",
       "      <td>0.8902</td>\n",
       "      <td>0.8873</td>\n",
       "      <td>0.8897</td>\n",
       "      <td>2432</td>\n",
       "      <td>2010-01-04 02:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.8896</td>\n",
       "      <td>0.8903</td>\n",
       "      <td>0.8887</td>\n",
       "      <td>0.8896</td>\n",
       "      <td>1287</td>\n",
       "      <td>2010-01-04 03:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.8896</td>\n",
       "      <td>0.8907</td>\n",
       "      <td>0.8883</td>\n",
       "      <td>0.8902</td>\n",
       "      <td>1090</td>\n",
       "      <td>2010-01-04 04:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53868</th>\n",
       "      <td>0.6741</td>\n",
       "      <td>0.6744</td>\n",
       "      <td>0.6730</td>\n",
       "      <td>0.6738</td>\n",
       "      <td>11098</td>\n",
       "      <td>2019-08-30 15:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53869</th>\n",
       "      <td>0.6738</td>\n",
       "      <td>0.6739</td>\n",
       "      <td>0.6730</td>\n",
       "      <td>0.6730</td>\n",
       "      <td>2422</td>\n",
       "      <td>2019-08-30 16:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53870</th>\n",
       "      <td>0.6730</td>\n",
       "      <td>0.6731</td>\n",
       "      <td>0.6722</td>\n",
       "      <td>0.6725</td>\n",
       "      <td>2634</td>\n",
       "      <td>2019-08-30 17:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53871</th>\n",
       "      <td>0.6724</td>\n",
       "      <td>0.6731</td>\n",
       "      <td>0.6721</td>\n",
       "      <td>0.6730</td>\n",
       "      <td>1589</td>\n",
       "      <td>2019-08-30 18:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53872</th>\n",
       "      <td>0.6731</td>\n",
       "      <td>0.6738</td>\n",
       "      <td>0.6730</td>\n",
       "      <td>0.6738</td>\n",
       "      <td>2939</td>\n",
       "      <td>2019-08-30 20:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>53873 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       AD_open  AD_high  AD_low  AD_close  AD_volume            datetime\n",
       "0       0.8927   0.8933  0.8901    0.8909       1937 2010-01-04 00:00:00\n",
       "1       0.8910   0.8917  0.8887    0.8887       2148 2010-01-04 01:00:00\n",
       "2       0.8891   0.8902  0.8873    0.8897       2432 2010-01-04 02:00:00\n",
       "3       0.8896   0.8903  0.8887    0.8896       1287 2010-01-04 03:00:00\n",
       "4       0.8896   0.8907  0.8883    0.8902       1090 2010-01-04 04:00:00\n",
       "...        ...      ...     ...       ...        ...                 ...\n",
       "53868   0.6741   0.6744  0.6730    0.6738      11098 2019-08-30 15:00:00\n",
       "53869   0.6738   0.6739  0.6730    0.6730       2422 2019-08-30 16:00:00\n",
       "53870   0.6730   0.6731  0.6722    0.6725       2634 2019-08-30 17:00:00\n",
       "53871   0.6724   0.6731  0.6721    0.6730       1589 2019-08-30 18:00:00\n",
       "53872   0.6731   0.6738  0.6730    0.6738       2939 2019-08-30 20:00:00\n",
       "\n",
       "[53873 rows x 6 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, name in zip(range(len(ds)), products_):\n",
    "    ds[i].to_hdf(name + \"_1h.hdf\", 'table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('*.hdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "products_ = []\n",
    "ds = []\n",
    "for file in files:\n",
    "    d = pd.read_hdf(file, 'table')\n",
    "    ds.append(d)\n",
    "    products_.append(d.columns[0].split('_')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AD',\n",
       " 'BP',\n",
       " 'BR',\n",
       " 'CD',\n",
       " 'CL',\n",
       " 'DX',\n",
       " 'EMD',\n",
       " 'EU',\n",
       " 'FV',\n",
       " 'GC',\n",
       " 'GF',\n",
       " 'HE',\n",
       " 'HG',\n",
       " 'LB',\n",
       " 'NG',\n",
       " 'NQ',\n",
       " 'PL',\n",
       " 'PX',\n",
       " 'RA',\n",
       " 'RU',\n",
       " 'SF',\n",
       " 'SI',\n",
       " 'S',\n",
       " 'TU',\n",
       " 'TY',\n",
       " 'US',\n",
       " 'W']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, opt, sc, loss, train_loader, val_loader, model_name):\n",
    "    vc = 0\n",
    "    early_stopping_rounds = 30\n",
    "    counter = 0\n",
    "    for e in range(100):\n",
    "        train_loss = 0\n",
    "        model.train()\n",
    "        for batch_x, batch_y_his, batch_y in tqdm(train_loader):\n",
    "            batch_x = batch_x.cuda()\n",
    "            batch_y = batch_y.cuda()\n",
    "            batch_y_his = batch_y_his.cuda()\n",
    "            \n",
    "            opt.zero_grad()\n",
    "            \n",
    "            output = model(batch_x, batch_y_his)\n",
    "            \n",
    "            l = loss(output, batch_y)\n",
    "            \n",
    "            l.backward()\n",
    "            \n",
    "            opt.step()\n",
    "            \n",
    "            train_loss += l.item()\n",
    "            \n",
    "        sc.step()\n",
    "        val_loss = 0\n",
    "        \n",
    "        true = []\n",
    "        preds = []\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch_x, batch_y_his, batch_y in val_loader:\n",
    "                batch_x = batch_x.cuda()\n",
    "                batch_y = batch_y.cuda()\n",
    "                batch_y_his = batch_y_his.cuda()\n",
    "                \n",
    "                output = model(batch_x, batch_y_his)\n",
    "            \n",
    "                l = loss(output, batch_y)\n",
    "                \n",
    "                val_loss += l.item()\n",
    "                \n",
    "                true.append(batch_y.detach().cpu().numpy())\n",
    "                preds.append(output.detach().cpu().numpy())\n",
    "        \n",
    "        true = np.concatenate(true)\n",
    "        preds = np.concatenate(preds)\n",
    "        \n",
    "        corr_score = []\n",
    "        acc_score = []\n",
    "        for ii in range(true.shape[1]):\n",
    "            r = pearsonr(true[:, ii], preds[:, ii])\n",
    "            corr_score.append(r[0])\n",
    "            t = true[:, ii].copy()\n",
    "            p = preds[:, ii].copy()\n",
    "            t[t>0] = 1\n",
    "            t[t<=0] = 0\n",
    "            p[p>0] = 1\n",
    "            p[p<=0] = 0\n",
    "            acc = accuracy_score(t, p)\n",
    "            acc_score.append(acc)\n",
    "            \n",
    "        corr_score = np.mean(corr_score)\n",
    "        acc_score = np.mean(acc_score)\n",
    "        \n",
    "        if vc < corr_score:\n",
    "            vc = corr_score\n",
    "            torch.save(model.state_dict(), model_name+'.pt')\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "        \n",
    "        if counter > early_stopping_rounds:\n",
    "            break\n",
    "        \n",
    "        print('Iter: ', e, 'train loss: ', train_loss, 'val loss: ', val_loss, 'val corr: ', corr_score, 'val acc: ', acc_score)\n",
    "        \n",
    "        idx = np.random.randint(0, len(batch_y))\n",
    "        \n",
    "        true_ = batch_y.cpu().numpy()[idx]\n",
    "        preds_ = output.detach().cpu().numpy()[idx]\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(true_)\n",
    "        plt.plot(preds_)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(model, loss, test_loader, model_name):\n",
    "    model.load_state_dict(torch.load(model_name+'.pt'))\n",
    "    \n",
    "    test_loss = 0\n",
    "        \n",
    "    true = []\n",
    "    preds = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y_his, batch_y in test_loader:\n",
    "            batch_x = batch_x.cuda()\n",
    "            batch_y = batch_y.cuda()\n",
    "            batch_y_his = batch_y_his.cuda()\n",
    "\n",
    "            output = model(batch_x, batch_y_his)\n",
    "\n",
    "            l = loss(output, batch_y)\n",
    "\n",
    "            test_loss += l.item()\n",
    "\n",
    "            true.append(batch_y.detach().cpu().numpy())\n",
    "            preds.append(output.detach().cpu().numpy())\n",
    "    \n",
    "    \n",
    "    test_loss /= len(test_loader)\n",
    "    \n",
    "    true = np.concatenate(true)\n",
    "    preds = np.concatenate(preds)\n",
    "\n",
    "    corr_score = []\n",
    "    acc_score = []\n",
    "    for ii in range(true.shape[1]):\n",
    "        r = pearsonr(true[:, ii], preds[:, ii])\n",
    "        corr_score.append(r[0])\n",
    "        t = true[:, ii].copy()\n",
    "        p = preds[:, ii].copy()\n",
    "        t[t>0] = 1\n",
    "        t[t<=0] = 0\n",
    "        p[p>0] = 1\n",
    "        p[p<=0] = 0\n",
    "        acc = accuracy_score(t, p)\n",
    "        acc_score.append(acc)\n",
    "\n",
    "    corr_score = np.mean(corr_score)\n",
    "    acc_score = np.mean(acc_score)\n",
    "    \n",
    "    return test_loss, corr_score, acc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "class InputAttentionEncoder(torch.jit.ScriptModule):\n",
    "    \n",
    "    __constants__ = [\"M\", \"T\", \"N\"]\n",
    "    \n",
    "    def __init__(self, N, M, T, stateful=False):\n",
    "        \"\"\"\n",
    "        :param: N: int\n",
    "            number of time serieses\n",
    "        :param: M:\n",
    "            number of LSTM units\n",
    "        :param: T:\n",
    "            number of timesteps\n",
    "        :param: stateful:\n",
    "            decides whether to initialize cell state of new time window with values of the last cell state\n",
    "            of previous time window or to initialize it with zeros\n",
    "        \"\"\"\n",
    "        super(self.__class__, self).__init__()\n",
    "        self.N = N\n",
    "        self.M = M\n",
    "        self.T = T\n",
    "        \n",
    "        self.encoder_lstm = nn.LSTMCell(input_size=self.N, hidden_size=self.M)\n",
    "        \n",
    "        #equation 8 matrices\n",
    "        \n",
    "        self.W_e = nn.Linear(2*self.M, self.T)\n",
    "        self.U_e = nn.Linear(self.T, self.T, bias=False)\n",
    "        self.v_e = nn.Linear(self.T, 1, bias=False)\n",
    "    \n",
    "    @torch.jit.script_method\n",
    "    def forward(self, inputs):\n",
    "        \n",
    "        encoded_inputs = torch.jit.annotate(List[Tensor], [])\n",
    "        \n",
    "        #initiale hidden states\n",
    "        h_tm1 = torch.zeros((inputs.size(0), self.M)).cuda()\n",
    "        s_tm1 = torch.zeros((inputs.size(0), self.M)).cuda()\n",
    "        \n",
    "        for t in range(self.T):\n",
    "            #concatenate hidden states\n",
    "            h_c_concat = torch.cat((h_tm1, s_tm1), dim=1)\n",
    "            \n",
    "            #attention weights for each k in N (equation 8)\n",
    "            x = self.W_e(h_c_concat).unsqueeze_(1).repeat(1, self.N, 1)\n",
    "            y = self.U_e(inputs.permute(0, 2, 1))\n",
    "            z = torch.tanh(x + y)\n",
    "            e_k_t = torch.squeeze(self.v_e(z))\n",
    "        \n",
    "            #normalize attention weights (equation 9)\n",
    "            alpha_k_t = F.softmax(e_k_t, dim=1)\n",
    "            \n",
    "            #weight inputs (equation 10)\n",
    "            weighted_inputs = alpha_k_t * inputs[:, t, :] \n",
    "    \n",
    "            #calculate next hidden states (equation 11)\n",
    "            h_tm1, s_tm1 = self.encoder_lstm(weighted_inputs, (h_tm1, s_tm1))\n",
    "            \n",
    "            encoded_inputs += [h_tm1]\n",
    "        encoded_inputs = torch.stack(encoded_inputs)\n",
    "        encoded_inputs = encoded_inputs.permute(1, 0, 2)\n",
    "        return encoded_inputs\n",
    "    \n",
    "class TemporalAttentionDecoder(torch.jit.ScriptModule):\n",
    "    \n",
    "    __constants__ = [\"P\", \"T\"]\n",
    "    \n",
    "    def __init__(self, M, P, T, stateful=False, horizon=6):\n",
    "        \"\"\"\n",
    "        :param: M: int\n",
    "            number of encoder LSTM units\n",
    "        :param: P:\n",
    "            number of deocder LSTM units\n",
    "        :param: T:\n",
    "            number of timesteps\n",
    "        :param: stateful:\n",
    "            decides whether to initialize cell state of new time window with values of the last cell state\n",
    "            of previous time window or to initialize it with zeros\n",
    "        \"\"\"\n",
    "        super(self.__class__, self).__init__()\n",
    "        self.M = M\n",
    "        self.P = P\n",
    "        self.T = T\n",
    "        self.stateful = stateful\n",
    "        \n",
    "        self.decoder_lstm = nn.LSTMCell(input_size=1, hidden_size=self.P)\n",
    "        \n",
    "        #equation 12 matrices\n",
    "        self.W_d = nn.Linear(2*self.P, self.M)\n",
    "        self.U_d = nn.Linear(self.M, self.M, bias=False)\n",
    "        self.v_d = nn.Linear(self.M, 1, bias = False)\n",
    "        \n",
    "        #equation 15 matrix\n",
    "        self.w_tilda = nn.Linear(self.M + horizon, 1)\n",
    "        \n",
    "        #equation 22 matrices\n",
    "        self.W_y = nn.Linear(self.P + self.M, self.P)\n",
    "        self.v_y = nn.Linear(self.P, horizon)\n",
    "    \n",
    "    @torch.jit.script_method\n",
    "    def forward(self, encoded_inputs, y):\n",
    "        \n",
    "        #initializing hidden states\n",
    "        d_tm1 = torch.zeros((encoded_inputs.size(0), self.P)).cuda()\n",
    "        s_prime_tm1 = torch.zeros((encoded_inputs.size(0), self.P)).cuda()\n",
    "        c_t = torch.zeros((encoded_inputs.size(0), self.P)).cuda()\n",
    "        for t in range(self.T):\n",
    "            #concatenate hidden states\n",
    "            d_s_prime_concat = torch.cat((d_tm1, s_prime_tm1), dim=1)\n",
    "            #print(d_s_prime_concat)\n",
    "            #temporal attention weights (equation 12)\n",
    "            x1 = self.W_d(d_s_prime_concat).unsqueeze_(1).repeat(1, encoded_inputs.shape[1], 1)\n",
    "            y1 = self.U_d(encoded_inputs)\n",
    "            z1 = torch.tanh(x1 + y1)\n",
    "            l_i_t = self.v_d(z1)\n",
    "            \n",
    "            #normalized attention weights (equation 13)\n",
    "            beta_i_t = F.softmax(l_i_t, dim=1)\n",
    "            \n",
    "            #create context vector (equation_14)\n",
    "            c_t = torch.sum(beta_i_t * encoded_inputs, dim=1)\n",
    "            \n",
    "            #concatenate c_t and y_t\n",
    "            y_c_concat = torch.cat((c_t, y[:, t, :]), dim=1)\n",
    "            #create y_tilda\n",
    "            y_tilda_t = self.w_tilda(y_c_concat)\n",
    "            \n",
    "            #calculate next hidden states (equation 16)\n",
    "            d_tm1, s_prime_tm1 = self.decoder_lstm(y_tilda_t, (d_tm1, s_prime_tm1))\n",
    "        \n",
    "        #concatenate context vector at step T and hidden state at step T\n",
    "        d_c_concat = torch.cat((d_tm1, c_t), dim=1)\n",
    "\n",
    "        #calculate output\n",
    "        y_Tp1 = self.v_y(self.W_y(d_c_concat))\n",
    "        return y_Tp1\n",
    "    \n",
    "class DARNN(torch.jit.ScriptModule):\n",
    "    def __init__(self, N, M, P, T, stateful_encoder=False, stateful_decoder=False):\n",
    "        super(self.__class__, self).__init__()\n",
    "        self.encoder = InputAttentionEncoder(N, M, T, stateful_encoder).cuda()\n",
    "        self.decoder = TemporalAttentionDecoder(M, P, T, stateful_decoder).cuda()\n",
    "    \n",
    "    @torch.jit.script_method\n",
    "    def forward(self, X_history, y_history):\n",
    "        out = self.decoder(self.encoder(X_history), y_history)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HSGLayer(nn.Module):\n",
    "    def __init__(self, n_units, init_gates_closed):\n",
    "        super(HSGLayer, self).__init__()\n",
    "        self.W_R = nn.Linear(n_units, n_units, bias=False)\n",
    "        self.W_F = nn.Linear(n_units, n_units)\n",
    "        if init_gates_closed:\n",
    "            self.W_F.bias = nn.Parameter(torch.Tensor([-2.5]*n_units).cuda())\n",
    "    def forward(self, s_L_t, s_prime_tm1):\n",
    "        g = torch.sigmoid(self.W_R(s_prime_tm1) + self.W_F(s_L_t))\n",
    "        s_prime_t = g*s_prime_tm1 + (1 - g)*s_L_t\n",
    "        return s_prime_t\n",
    "\n",
    "class RHNCell(nn.Module):\n",
    "    def __init__(self, in_feats, n_units, rec_depth=3, couple_gates=True,\n",
    "                 use_HSG=False, init_gates_closed=False):\n",
    "        super(RHNCell, self).__init__()\n",
    "        self.rec_depth = rec_depth\n",
    "        self.in_feats = in_feats\n",
    "        self.n_units = n_units\n",
    "        self.couple_gates = couple_gates\n",
    "        self.use_HSG = use_HSG\n",
    "        self.W_H = nn.Linear(in_feats, n_units, bias=False)\n",
    "        self.W_T = nn.Linear(in_feats, n_units, bias=False)\n",
    "        if not couple_gates:\n",
    "            self.W_C = nn.Linear(in_feats, n_units, bias=False)\n",
    "        self.R_H = nn.ModuleList([nn.Linear(n_units, n_units) for _ in range(rec_depth)])\n",
    "        self.R_T = nn.ModuleList([nn.Linear(n_units, n_units) for _ in range(rec_depth)])\n",
    "        if not couple_gates:\n",
    "            self.R_C = nn.ModuleList([nn.Linear(n_units, n_units) for _ in range(rec_depth)])\n",
    "        \n",
    "        if use_HSG:\n",
    "            self.HSG = HSGLayer(n_units, init_gates_closed)\n",
    "        \n",
    "        if init_gates_closed:\n",
    "            for l in range(rec_depth):\n",
    "                self.R_T[l].bias = nn.Parameter(torch.Tensor([-2.5]*n_units).cuda())\n",
    "                if not couple_gates:\n",
    "                    self.R_C[l].bias = nn.Parameter(torch.Tensor([-2.5]*n_units).cuda())\n",
    "        \n",
    "    def forward(self, x, s):\n",
    "        if self.use_HSG:\n",
    "            s_prime_tm1 = s\n",
    "        preds = []\n",
    "        for l in range(self.rec_depth):\n",
    "            if l == 0:\n",
    "                h_l_t = torch.tanh(self.W_H(x) + self.R_H[l](s))\n",
    "                t_l_t = torch.sigmoid(self.W_T(x) + self.R_T[l](s))\n",
    "                if not self.couple_gates:\n",
    "                    c_l_t = torch.sigmoid(self.W_C(x) + self.R_C[l](s))\n",
    "            else:\n",
    "                h_l_t = torch.tanh(self.R_H[l](s))\n",
    "                t_l_t = torch.sigmoid(self.R_T[l](s))\n",
    "                if not self.couple_gates:\n",
    "                    c_l_t = torch.sigmoid(self.R_C[l](s))\n",
    "            \n",
    "            if not self.couple_gates:\n",
    "                s = h_l_t*t_l_t + c_l_t*s\n",
    "            else:\n",
    "                s = h_l_t*t_l_t + (1 - t_l_t)*s\n",
    "            preds.append(s)\n",
    "                \n",
    "        if self.use_HSG:\n",
    "            s = self.HSG(s, s_prime_tm1)\n",
    "            preds.pop()\n",
    "            preds.append(s)\n",
    "        preds = torch.stack(preds)\n",
    "        return s, preds\n",
    "\n",
    "    \n",
    "class RHN(nn.Module):\n",
    "    def __init__(self, in_feats, out_feats, n_units=32, rec_depth=3, couple_gates=True, use_HSG=False,\n",
    "                 init_gates_closed=False, use_batch_norm=False):\n",
    "        super(RHN, self).__init__()\n",
    "        assert rec_depth > 0\n",
    "        self.rec_depth = rec_depth\n",
    "        self.in_feats = in_feats\n",
    "        self.n_units = n_units\n",
    "        self.init_gates_closed = init_gates_closed\n",
    "        self.couple_gates = couple_gates\n",
    "        self.use_HSG = use_HSG\n",
    "        self.use_batch_norm = use_batch_norm\n",
    "        self.RHNCell = RHNCell(in_feats, n_units, rec_depth, couple_gates=couple_gates,\n",
    "                               use_HSG=use_HSG, init_gates_closed=init_gates_closed)\n",
    "        if use_batch_norm:\n",
    "            self.bn_x = nn.BatchNorm1d(in_feats)\n",
    "            self.bn_s = nn.BatchNorm1d(n_units)\n",
    "    def forward(self, x):\n",
    "        s = torch.zeros(x.shape[0], self.n_units).cuda()\n",
    "        preds = []\n",
    "        highway_states = []\n",
    "        for t in range(x.shape[1]):\n",
    "            if self.use_batch_norm:\n",
    "                x_inp = self.bn_x(x[:, t, :])\n",
    "                s = self.bn_s(s)\n",
    "            else:\n",
    "                x_inp = x[:, t, :]\n",
    "            s, all_s = self.RHNCell(x_inp, s)\n",
    "            preds.append(s)\n",
    "            highway_states.append(all_s)\n",
    "        preds = torch.stack(preds)\n",
    "        preds = preds.permute(1, 0, 2)\n",
    "        highway_states = torch.stack(highway_states)\n",
    "        highway_states = highway_states.permute(2, 0, 3, 1)\n",
    "        out = preds\n",
    "        \n",
    "        return out, highway_states\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, T, in_channels, n_filters=32, filter_size=5):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        padding1 = self._calc_padding(T, filter_size)\n",
    "        self.conv = nn.Conv1d(in_channels, n_filters, filter_size, padding=padding1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.AdaptiveMaxPool1d(T)\n",
    "        self.zp = nn.ConstantPad1d((1, 0), 0)\n",
    "    def _calc_padding(self, Lin, kernel, stride=1, dilation=1):\n",
    "        p = int(((Lin - 1) * stride + 1 + dilation * (kernel - 1) - Lin) / 2)\n",
    "        return p\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.conv(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class HARHN(nn.Module):\n",
    "    def __init__(self, n_conv_layers, T, in_feats, target_feats, n_units_enc=32, n_units_dec=32, enc_input_size=32, rec_depth=3,\n",
    "                 out_feats=1, n_filters=32, filter_size=5):\n",
    "        super(HARHN, self).__init__()\n",
    "        assert n_conv_layers > 0\n",
    "        self.n_convs = n_conv_layers\n",
    "        self.n_units_enc = n_units_enc\n",
    "        self.n_units_dec = n_units_dec\n",
    "        self.rec_depth = rec_depth\n",
    "        self.T = T\n",
    "        self.convs = nn.ModuleList([ConvBlock(T, in_feats, n_filters=n_filters, filter_size=filter_size) if i == 0 else ConvBlock(T, n_filters, n_filters=n_filters, filter_size=filter_size) for i in range(n_conv_layers)])\n",
    "        self.conv_to_enc = nn.Linear(n_filters, enc_input_size)\n",
    "        self.RHNEncoder = RHN(enc_input_size, out_feats=n_units_enc, n_units=n_units_enc, rec_depth=rec_depth)\n",
    "        self.RHNDecoder = RHNCell(target_feats, n_units_dec, rec_depth=rec_depth)\n",
    "        self.T_k = nn.ModuleList([nn.Linear(n_units_dec, n_units_enc, bias=False) for i in range(self.rec_depth)])\n",
    "        self.U_k = nn.ModuleList([nn.Linear(n_units_enc, n_units_enc) for i in range(self.rec_depth)])\n",
    "        self.v_k = nn.ModuleList([nn.Linear(n_units_enc, 1) for i in range(self.rec_depth)])\n",
    "        self.W_tilda = nn.Linear(target_feats, target_feats, bias=False)\n",
    "        self.V_tilda = nn.Linear(rec_depth*n_units_enc, target_feats)\n",
    "        self.W = nn.Linear(n_units_dec, target_feats)\n",
    "        self.V = nn.Linear(rec_depth*n_units_enc, target_feats)\n",
    "    def forward(self, x, y):\n",
    "        for l in range(self.n_convs):\n",
    "            x = self.convs[l](x)\n",
    "        x = self.conv_to_enc(x)\n",
    "        x, h_T_L = self.RHNEncoder(x) # h_T_L.shape = (batch_size, T, n_units_enc, rec_depth)\n",
    "        s = torch.zeros(x.shape[0], self.n_units_dec).cuda()\n",
    "        for t in range(self.T):\n",
    "            s_rep = s.unsqueeze(1)\n",
    "            s_rep = s_rep.repeat(1, self.T, 1)\n",
    "            d_t = []\n",
    "            for k in range(self.rec_depth):\n",
    "                h_T_k = h_T_L[..., k]\n",
    "                a = self.U_k[k](h_T_k)\n",
    "                b = self.T_k[k](s_rep)\n",
    "                e_t_k = self.v_k[k](torch.tanh(self.T_k[k](s_rep) + self.U_k[k](h_T_k)))\n",
    "                alpha_t_k = torch.softmax(e_t_k, 1)\n",
    "                d_t_k = torch.sum(h_T_k*alpha_t_k, dim=1)\n",
    "                d_t.append(d_t_k)\n",
    "            d_t = torch.cat(d_t, dim=1)\n",
    "            y_tilda_t = self.W_tilda(y[:, t, :]) + self.V_tilda(d_t)\n",
    "            s, _ = self.RHNDecoder(y_tilda_t, s)\n",
    "        \n",
    "        y_T = self.W(s) + self.V(d_t)\n",
    "        return y_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon = 6\n",
    "depth = 64\n",
    "test_scores = {}\n",
    "DEBUG = True\n",
    "if DEBUG:\n",
    "    length = 1\n",
    "else:\n",
    "    length = len(products_)\n",
    "for i in range(len(products_[:length])):\n",
    "    test_scores[products_[i]] = {}\n",
    "    \n",
    "    \n",
    "    df = ds[i]\n",
    "    corr_dict = {}\n",
    "    \n",
    "    open_col = products_[i] + \"_open\"\n",
    "    close_col = products_[i] + \"_close\"\n",
    "    \n",
    "    ys = []\n",
    "    for j in range(1, horizon+1):\n",
    "        ys.append(df[close_col].shift(-j).ffill().values/df[open_col].values - 1)\n",
    "        \n",
    "    for j in range(len(ds)):\n",
    "        if j != i:\n",
    "            df = pd.merge(df, ds[j], on='datetime', how='left')\n",
    "            df = df.ffill().bfill()\n",
    "            open_col = products_[j] + \"_open\"\n",
    "            close_col = products_[j] + \"_close\"\n",
    "            ys_ = []\n",
    "            for k in range(1, horizon+1):\n",
    "                ys_.append(df[close_col].shift(-k).ffill().values/df[open_col].values - 1)\n",
    "            \n",
    "            mean_corr = []\n",
    "            for v1, v2 in zip(ys, ys_):\n",
    "                corr = np.corrcoef(v1, v2)[0, 1]\n",
    "                mean_corr.append(corr)\n",
    "            mean_corr = np.mean(mean_corr)\n",
    "            \n",
    "            corr_dict[products_[j]] = mean_corr\n",
    "    \n",
    "    inv_corr_dict = {v: k for k, v in corr_dict.items()}\n",
    "    keys = list(inv_corr_dict)\n",
    "    keys = np.sort(keys)\n",
    "    corr_products = [products_[i]] + [inv_corr_dict[key] for key in list(keys)[:3] + list(keys)[-3:]]\n",
    "    \n",
    "    open_cols = [name for name in df.columns if 'open' in name and name.split('_')[0] in corr_products]\n",
    "    high_cols = [name for name in df.columns if 'high' in name and name.split('_')[0] in corr_products]\n",
    "    low_cols = [name for name in df.columns if 'low' in name and name.split('_')[0] in corr_products]\n",
    "    close_cols = [name for name in df.columns if 'close' in name and name.split('_')[0] in corr_products]\n",
    "    volume_cols = [name for name in df.columns if 'volume' in name and name.split('_')[0] in corr_products]\n",
    "    \n",
    "    for name in volume_cols:\n",
    "        df[name] = (df[name].values - df[name].values.mean())/df[name].values.std()\n",
    "        \n",
    "    open_diff1, high_diff1, low_diff1, close_diff1, volume_diff1 = [], [], [], [], []\n",
    "    open_diff2, high_diff2, low_diff2, close_diff2, volume_diff2 = [], [], [], [], []\n",
    "    returns_cols = []\n",
    "    for oc, hc, lc, cc, vc in zip(open_cols, high_cols, low_cols, close_cols, volume_cols):\n",
    "        df[oc+\"_d1\"] = df[oc].diff().bfill()\n",
    "        df[hc+\"_d1\"] = df[hc].diff().bfill()\n",
    "        df[lc+\"_d1\"] = df[lc].diff().bfill()\n",
    "        df[cc+\"_d1\"] = df[cc].diff().bfill()\n",
    "        df[vc+\"_d1\"] = df[vc].diff().bfill()\n",
    "        \n",
    "        df[oc+\"_d2\"] = df[oc+\"_d1\"].diff().bfill()\n",
    "        df[hc+\"_d2\"] = df[hc+\"_d1\"].diff().bfill()\n",
    "        df[lc+\"_d2\"] = df[lc+\"_d1\"].diff().bfill()\n",
    "        df[cc+\"_d2\"] = df[cc+\"_d1\"].diff().bfill()\n",
    "        df[vc+\"_d2\"] = df[vc+\"_d1\"].diff().bfill()\n",
    "        \n",
    "        open_diff1.append(oc+\"_d1\")\n",
    "        high_diff1.append(hc+\"_d1\")\n",
    "        low_diff1.append(lc+\"_d1\")\n",
    "        close_diff1.append(cc+\"_d1\")\n",
    "        volume_diff1.append(vc+\"_d1\")\n",
    "        \n",
    "        open_diff2.append(oc+\"_d2\")\n",
    "        high_diff2.append(hc+\"_d2\")\n",
    "        low_diff2.append(lc+\"_d2\")\n",
    "        close_diff2.append(cc+\"_d2\")\n",
    "        volume_diff2.append(vc+\"_d2\")\n",
    "        \n",
    "        df[oc.split('_')[0]+'_ret'] = df[cc].values/df[oc].values - 1\n",
    "        returns_cols.append(oc.split('_')[0]+'_ret')\n",
    "        \n",
    "        \n",
    "    cols_to_use = open_diff1 + high_diff1 + low_diff1 + close_diff1 + volume_diff1 +\\\n",
    "                  open_diff2 + high_diff2 + low_diff2 + close_diff2 + volume_diff2 + returns_cols\n",
    "    X = np.zeros((len(df), depth, len(cols_to_use)))\n",
    "    for k, name in enumerate(cols_to_use):\n",
    "        for l in range(depth):\n",
    "            X[:, l, k] = df[name].shift(depth - l - 1).bfill()\n",
    "    \n",
    "    y = np.concatenate([y_.reshape(-1, 1) for y_ in ys], axis=1)\n",
    "    \n",
    "    y_his = np.zeros((len(y), depth, y.shape[1]))\n",
    "    for k in range(y.shape[1]):\n",
    "        for l in range(depth):\n",
    "            y_his[:, l, k] = pd.Series(y[:, k]).shift(depth - l + horizon).bfill()\n",
    "    \n",
    "    train_length = int(0.6*len(X))\n",
    "    val_length = int(0.1*len(X))\n",
    "    \n",
    "    X_train = X[:train_length]\n",
    "    X_val = X[train_length:train_length+val_length]\n",
    "    X_test = X[train_length+val_length:]\n",
    "    \n",
    "    y_train = y[:train_length]\n",
    "    y_val = y[train_length:train_length+val_length]\n",
    "    y_test = y[train_length+val_length:]\n",
    "    \n",
    "    y_his_train = y_his[:train_length]\n",
    "    y_his_val = y_his[train_length:train_length+val_length]\n",
    "    y_his_test = y_his[train_length+val_length:]\n",
    "    \n",
    "    X_train_t = torch.Tensor(X_train)\n",
    "    X_val_t = torch.Tensor(X_val)\n",
    "    X_test_t = torch.Tensor(X_test)\n",
    "    \n",
    "    y_train_t = torch.Tensor(y_train)\n",
    "    y_val_t = torch.Tensor(y_val)\n",
    "    y_test_t = torch.Tensor(y_test)\n",
    "    \n",
    "    y_his_train_t = torch.Tensor(y_his_train)\n",
    "    y_his_val_t = torch.Tensor(y_his_val)\n",
    "    y_his_test_t = torch.Tensor(y_his_test)\n",
    "    \n",
    "    train_loader = DataLoader(TensorDataset(X_train_t, y_his_train_t, y_train_t), shuffle=True, batch_size=64)\n",
    "    val_loader = DataLoader(TensorDataset(X_val_t, y_his_val_t, y_val_t), shuffle=False, batch_size=64)\n",
    "    test_loader = DataLoader(TensorDataset(X_test_t, y_his_test_t, y_test_t), shuffle=False, batch_size=64)\n",
    "    \n",
    "    model = DARNN(len(cols_to_use), 128, 128, depth).cuda()\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    sc = torch.optim.lr_scheduler.StepLR(opt, 10, 0.9)\n",
    "    loss = nn.SmoothL1Loss()\n",
    "    model_name = 'darnn1'\n",
    "    \n",
    "    train(model, opt, sc, loss, train_loader, val_loader, model_name)\n",
    "    test_loss, test_corr, test_acc = infer(model, loss, test_loader, model_name)\n",
    "    \n",
    "    test_scores[products_[i]][model_name] = {}\n",
    "    test_scores[products_[i]][model_name]['test mae'] = test_loss\n",
    "    test_scores[products_[i]][model_name]['test corr'] = test_corr\n",
    "    test_scores[products_[i]][model_name]['test acc'] = test_acc\n",
    "\n",
    "    model = HARHN(3, depth, len(cols_to_use), 6, n_units_enc=128, n_units_dec=128).cuda()\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    sc = torch.optim.lr_scheduler.StepLR(opt, 10, 0.9)\n",
    "    loss = nn.SmoothL1Loss()\n",
    "    model_name = 'harhn'\n",
    "    \n",
    "    train(model, opt, sc, loss, train_loader, val_loader, model_name)\n",
    "    test_loss, test_corr, test_acc = infer(model, loss, test_loader, model_name)\n",
    "    \n",
    "    test_scores[products_[i]][model_name] = {}\n",
    "    test_scores[products_[i]][model_name]['test mae'] = test_loss\n",
    "    test_scores[products_[i]][model_name]['test corr'] = test_corr\n",
    "    test_scores[products_[i]][model_name]['test acc'] = test_acc\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batch_y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-ce9ddadf18a7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbatch_y\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'batch_y' is not defined"
     ]
    }
   ],
   "source": [
    "batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AD': {'darnn1': {'test mae': 3.194358374357151e-06,\n",
       "   'test corr': 0.003190281904119308,\n",
       "   'test acc': 0.48622367959743445},\n",
       "  'harhn': {'test mae': 8.234382225461232e-06,\n",
       "   'test corr': 0.0452568651098199,\n",
       "   'test acc': 0.5152818164944627}}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results2.json', 'w') as f:\n",
    "    f.write(json.dumps(test_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53873, 64, 77)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53873, 6)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
